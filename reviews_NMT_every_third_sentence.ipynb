{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review generation as Neural Machine Translation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "def preprocess_sentence(w):\n",
    "    w = w.lower().strip()\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(num_reviews):\n",
    "    ds = tfds.load('amazon_us_reviews/Video_Games_v1_00', data_dir='/hdd/tf_datasets', \n",
    "                   split='train', shuffle_files=True).take(num_reviews)\n",
    "    fields = [[i['data']['product_title'].decode(\"utf-8\"), \n",
    "               i['data']['review_body'].decode(\"utf-8\"), \n",
    "               i['data']['review_headline'].decode(\"utf-8\")] for i in ds.as_numpy_iterator()\n",
    "               if len(i['data']['review_body'].decode(\"utf-8\").split('.')) > 4 and \\\n",
    "                  len(i['data']['review_body'].decode(\"utf-8\")) > 20]\n",
    "    \n",
    "    x = [i[0] + ' reviewtitle ' + i[2] + ' reviewcontent ' + '. '.join(i[1].split('.')[::3]) for i in fields]\n",
    "    y = [i[1] for i in fields]\n",
    "\n",
    "    x = [preprocess_sentence(i) for i in x]\n",
    "    y = [preprocess_sentence(i) for i in y]\n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=3000, filters='', oov_token='<unk>')\n",
    "    tokenizer.fit_on_texts(x + y)\n",
    "    \n",
    "    x = tokenizer.texts_to_sequences(x)\n",
    "    y = tokenizer.texts_to_sequences(y)\n",
    "\n",
    "    x = tf.keras.preprocessing.sequence.pad_sequences(x, padding='post', maxlen=100)\n",
    "    y = tf.keras.preprocessing.sequence.pad_sequences(y, padding='post', maxlen=100)\n",
    "    \n",
    "    return x, y, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x, y, tokenizer = load_dataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ----> <start>\n",
      "113 ----> theresia\n",
      "73 ----> nintendo\n",
      "35 ----> ds\n",
      "46 ----> reviewtitle\n",
      "114 ----> going\n",
      "115 ----> retro\n",
      "116 ----> ?\n",
      "47 ----> reviewcontent\n",
      "74 ----> when\n",
      "11 ----> i\n",
      "36 ----> first\n",
      "75 ----> heard\n",
      "6 ----> of\n",
      "12 ----> this\n",
      "7 ----> game\n",
      "11 ----> i\n",
      "17 ----> was\n",
      "14 ----> really\n",
      "76 ----> curious\n",
      "77 ----> how\n",
      "8 ----> a\n",
      "23 ----> horror\n",
      "7 ----> game\n",
      "78 ----> would\n",
      "79 ----> work\n",
      "80 ----> out\n",
      "81 ----> on\n",
      "2 ----> the\n",
      "35 ----> ds\n",
      "3 ----> .\n",
      "4 ----> and\n",
      "2 ----> the\n",
      "82 ----> controls\n",
      "4 ----> and\n",
      "83 ----> interface\n",
      "24 ----> are\n",
      "84 ----> annoying\n",
      "3 ----> .\n",
      "13 ----> for\n",
      "25 ----> me\n",
      "12 ----> this\n",
      "14 ----> really\n",
      "85 ----> killed\n",
      "2 ----> the\n",
      "86 ----> mood\n",
      "6 ----> of\n",
      "2 ----> the\n",
      "7 ----> game\n",
      "4 ----> and\n",
      "37 ----> overall\n",
      "18 ----> just\n",
      "87 ----> slowed\n",
      "26 ----> things\n",
      "88 ----> down\n",
      "89 ----> too\n",
      "27 ----> much\n",
      "3 ----> .\n",
      "90 ----> paul\n",
      "20 ----> s\n",
      "91 ----> review\n",
      "6 ----> of\n",
      "2 ----> the\n",
      "28 ----> story\n",
      "16 ----> is\n",
      "92 ----> pretty\n",
      "27 ----> much\n",
      "10 ----> it\n",
      "3 ----> .\n",
      "29 ----> but\n",
      "30 ----> if\n",
      "38 ----> your\n",
      "18 ----> just\n",
      "31 ----> looking\n",
      "13 ----> for\n",
      "39 ----> something\n",
      "93 ----> new\n",
      "5 ----> ,\n",
      "40 ----> keep\n",
      "31 ----> looking\n",
      "22 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_words(tokenizer, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print (\"%d ----> %s\" % (t, tokenizer.index_word[t]))\n",
    "\n",
    "tokens_to_words(tokenizer, x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnxC7q-j3jFD"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, tokenizer = load_dataset(num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QILQkOs3jFG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10816 10816 2705 2705\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJPmLZGMeD5q"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXukARTDd7MT",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "20 ----> <start>\n",
      "2940 ----> riding\n",
      "1 ----> <unk>\n",
      "44 ----> reviewtitle\n",
      "32 ----> my\n",
      "882 ----> daughter\n",
      "12 ----> is\n",
      "5 ----> and\n",
      "340 ----> she\n",
      "620 ----> loves\n",
      "9 ----> it\n",
      "45 ----> reviewcontent\n",
      "32 ----> my\n",
      "882 ----> daughter\n",
      "12 ----> is\n",
      "5 ----> and\n",
      "340 ----> she\n",
      "1 ----> <unk>\n",
      "14 ----> this\n",
      "13 ----> game\n",
      "2 ----> .\n",
      "25 ----> have\n",
      "64 ----> fun\n",
      "21 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "20 ----> <start>\n",
      "32 ----> my\n",
      "882 ----> daughter\n",
      "12 ----> is\n",
      "5 ----> and\n",
      "340 ----> she\n",
      "1 ----> <unk>\n",
      "14 ----> this\n",
      "13 ----> game\n",
      "2 ----> .\n",
      "340 ----> she\n",
      "581 ----> plays\n",
      "9 ----> it\n",
      "38 ----> all\n",
      "3 ----> the\n",
      "62 ----> time\n",
      "2 ----> .\n",
      "83 ----> well\n",
      "196 ----> worth\n",
      "3 ----> the\n",
      "214 ----> money\n",
      "2 ----> .\n",
      "25 ----> have\n",
      "64 ----> fun\n",
      "2 ----> .\n",
      "21 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(tokenizer, input_tensor_train[3])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(tokenizer, target_tensor_train[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqHsArVZ3jFS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 16\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 128\n",
    "units = 256\n",
    "vocab_size = tokenizer.num_words\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qc6-NK1GtWQt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([16, 100]), TensorShape([16, 100]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## Encoder and decoder model\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, \n",
    "                                       return_state=True, recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60gSVh05Jl6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (16, 100, 256)\n",
      "Encoder Hidden state shape: (batch size, units) (16, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umohpBN2OM94"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "                self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k534zTHiDjQU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (16, 256)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (16, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, \n",
    "                                       return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5UY8wko3jFp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (16, 3000)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "## Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMVWzzsfNl4e"
   },
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hpObfY22IddU"
   },
   "source": [
    "## Training\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "#             tf.print(t)\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddefjBMa3jF0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for (batch, (inp, targ)) in tqdm(enumerate(dataset.take(steps_per_epoch))):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28766107a48>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = [4.4296, 3.9846, 3.8174, 3.7093, 3.6310, 3.5694, 3.5174, 3.4727, 3.4330, 3.3950, 3.3582, 3.3230, 3.2873, 3.2555, 3.2225, 3.1903, 3.1594, 3.1298, 3.1001, 3.0708, 3.0413, 3.0141, 2.9864, 2.9614, 2.9356, 2.9080, 2.8817, 2.8575, 2.8369, 2.8108, 2.7887, 2.7735, 2.7481, 2.7246, 2.7089, 2.6893, 2.6692, 2.6543, 2.6318, 2.6140, 2.5985, 2.5808, 2.5659, 2.5493, 2.5345, 2.5193, 2.5085, 2.4970, 2.4784, 2.4660, 2.4653, 2.4418, 2.4356, 2.4185, 2.4119, 2.4001, 2.3883, 2.3763, 2.3624, 2.3546, 2.3448, 2.3434, 2.3313, 2.3205, 2.3065, 2.2978, 2.3066, 2.2850, 2.2827, 2.2788, 2.2582, 2.2483, 2.2674, 2.2468, 2.2291, 2.2273, 2.2272, 2.2119, 2.2132, ]\n",
    "plt.plot(np.arange(len(history)), history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "## Translate\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbQpyYs13jF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5hQWlbN3jGF"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sl9zUHzg3jGI"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJpT9D5_OgP6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fab880a5d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> turtle reviewtitle i hate it <end>\n",
      "Predicted translation: <unk> <unk> . i m going to be a <unk> in sight . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'turtle reviewtitle i hate it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrAM0FDomq3E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> game reviewtitle good game this is <end>\n",
      "Predicted translation: game play . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'game reviewtitle good game this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrAM0FDomq3E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> game of blocks reviewtitle awful <end>\n",
      "Predicted translation: game . i m satisfied . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'game of blocks reviewtitle awful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrAM0FDomq3E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> game of blocks reviewtitle good but bad <end>\n",
      "Predicted translation: fun and i m satisfied . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'game of blocks reviewtitle good but bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam search on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(sentence, guesses_number, width=100):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = int(tokenizer.word_index['<start>'])\n",
    "\n",
    "    top_guesses = []\n",
    "    current_guesses = [[[dec_input], tf.identity(dec_hidden), 0]]\n",
    "    for t in range(max_length_targ):\n",
    "        current_guesses_expanded = []\n",
    "        # Iterate over all current coditions\n",
    "        for guess in current_guesses:\n",
    "            dec_input = tf.expand_dims([guess[0][-1]], 0)\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, guess[1], enc_out)\n",
    "            predictions = tf.nn.softmax(predictions[0])\n",
    "            \n",
    "            top_ids = tf.argsort(predictions, direction='DESCENDING')[:width]\n",
    "            scores = guess[2] + tf.math.log(tf.clip_by_value(tf.gather(predictions, top_ids), 0.001, 1))\n",
    "            \n",
    "            # Add new word ids\n",
    "            word_ids = [guess[0] + [int(id)] for id in top_ids]\n",
    "\n",
    "            current_guesses_expanded += list(np.array([word_ids, \n",
    "                                                       [dec_hidden] * width, \n",
    "                                                       scores.numpy().tolist()]).T)\n",
    "        \n",
    "        current_guesses = sorted(current_guesses_expanded, key=lambda x: -x[2])[:width]\n",
    "        \n",
    "        # Add guess to top_guesses if encounter <end> token\n",
    "        done_idxs = [guess_idx for guess_idx in range(len(current_guesses))\n",
    "                     if tokenizer.index_word[int(current_guesses[guess_idx][0][-1])] == '<end>']\n",
    "        done_guesses = np.take(current_guesses, done_idxs, axis=0)\n",
    "        # Normalize score by length\n",
    "        done_guesses = [[guess[0], guess[2] / (t+1)] for guess in done_guesses]\n",
    "        top_guesses += done_guesses\n",
    "        current_guesses = [guess for idx, guess in enumerate(current_guesses)\n",
    "                           if idx not in done_idxs]\n",
    "        \n",
    "        if len(current_guesses) == 0 or len(top_guesses) >= guesses_number:\n",
    "            break\n",
    "    \n",
    "    top_guesses.sort(key=lambda x: -x[1])\n",
    "    for i, guess in enumerate(top_guesses):\n",
    "        top_guesses[i][0] = ' '.join(tokenizer.index_word[predicted_id] for predicted_id in guess[0])\n",
    "    return top_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turtle reviewtitle i hate it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<start> <unk> fan . <end>', -1.262439250946045],\n",
       " ['<start> <unk> <unk> . <end>', -1.4593329429626465],\n",
       " ['<start> ever <unk> . <end>', -1.477128267288208],\n",
       " ['<start> ever had . <end>', -1.518937110900879],\n",
       " ['<start> ever seen . <end>', -1.5623829364776611],\n",
       " ['<start> game <unk> . <end>', -1.5928157567977905],\n",
       " ['<start> ever opened . <end>', -1.6117451190948486],\n",
       " ['<start> <unk> finish . <end>', -1.6639404296875],\n",
       " ['<start> game had . <end>', -1.739352822303772],\n",
       " ['<start> <unk> died . <end>', -1.743628978729248],\n",
       " ['<start> <unk> work . <end>', -1.768803596496582],\n",
       " ['<start> ever attached . <end>', -1.7690125703811646],\n",
       " ['<start> in places . <end>', -1.793155550956726],\n",
       " ['<start> game work . <end>', -1.8053075075149536],\n",
       " ['<start> ever used . <end>', -1.822326421737671],\n",
       " ['<start> <unk> dog . <end>', -1.8853189945220947],\n",
       " ['<start> happens . <end>', -2.097435633341471]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "game reviewtitle good game this is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<start> game play . <end>', -1.2143914699554443],\n",
       " ['<start> game ever . <end>', -1.4110758304595947],\n",
       " ['<start> good game . <end>', -1.5447962284088135],\n",
       " ['<start> ever made . <end>', -1.5718624591827393],\n",
       " ['<start> fun game . <end>', -1.6512558460235596],\n",
       " ['<start> different experience . <end>', -1.7071799039840698],\n",
       " ['<start> battlefield type . <end>', -1.7381821870803833],\n",
       " ['<start> graphics fan . <end>', -1.7882578372955322],\n",
       " ['<start> game plays . <end>', -1.837547779083252],\n",
       " ['<start> game has . <end>', -1.8395144939422607],\n",
       " ['<start> battlefield good . <end>', -1.8576164245605469],\n",
       " ['<start> entertaining game . <end>', -1.8805241584777832],\n",
       " ['<start> plot twist . <end>', -1.8896340131759644],\n",
       " ['<start> game . . <end>', -1.9018771648406982],\n",
       " ['<start> game . <end>', -2.0283168156941733],\n",
       " ['<start> battlefield . <end>', -2.0291603406270347]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "game of blocks reviewtitle awful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<start> wow . <end>', -1.6562786102294922],\n",
       " ['<start> great game <end>', -1.6784863471984863],\n",
       " ['<start> great graphics <end>', -1.6950899759928386],\n",
       " ['<start> game . <end>', -1.8375898996988933],\n",
       " ['<start> fun . <end>', -2.020284334818522],\n",
       " ['<start> user interface <end>', -2.0372241338094077],\n",
       " ['<start> great gameplay <end>', -2.148651123046875],\n",
       " ['<start> c <unk> <end>', -2.241889317830404],\n",
       " ['<start> video game <end>', -2.243744214375814],\n",
       " ['<start> endless <unk> <end>', -2.2802206675211587],\n",
       " ['<start> c <end>', -2.8234329223632812],\n",
       " ['<start> sure <end>', -2.956500291824341],\n",
       " ['<start> . <end>', -2.9684572219848633],\n",
       " ['<start> game <end>', -3.0092759132385254],\n",
       " ['<start> dlc <end>', -3.0684807300567627],\n",
       " ['<start> <unk> <end>', -3.1416046619415283],\n",
       " ['<start> gameplay <end>', -3.1476223468780518],\n",
       " ['<start> sense <end>', -3.2024102210998535],\n",
       " ['<start> <end>', -6.400173187255859]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fly and jump game reviewtitle i am in love\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<start> fun . <end>', -1.2186179955800374],\n",
       " ['<start> ok . <end>', -1.3222084045410156],\n",
       " ['<start> <unk> . <end>', -1.6134808858235676],\n",
       " ['<start> best . <end>', -1.9635475476582844],\n",
       " ['<start> great . <end>', -2.1374050776163735],\n",
       " ['<start> played . <end>', -2.1409972508748374],\n",
       " ['<start> required . <end>', -2.185060660044352],\n",
       " ['<start> played it <end>', -2.195972124735514],\n",
       " ['<start> wow . <end>', -2.241674264272054],\n",
       " ['<start> played <end>', -2.901339054107666],\n",
       " ['<start> <unk> <end>', -2.974656105041504]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for string in [u'turtle reviewtitle i hate it',\n",
    "               u'game reviewtitle good game this is',\n",
    "               u'game of blocks reviewtitle awful',\n",
    "               u'fly and jump game reviewtitle i am in love']:\n",
    "    print(string)\n",
    "    display(beam_search(string, guesses_number=10, width=100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks at condition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21, 108,   6, 109, 110,  46, 111, 112,  47,  14,  48,  12,   7,\n",
       "         3,  49,   3,  50,  51,  17,  52,  53,  54,   4,  10,  14,  55,\n",
       "        56,  57,  15,  58,  59,  19,   2,  60,   3,  10,  20,   8,  61,\n",
       "        62,   9,  32,   2,  63,  33,  64,  65,  66,   5,   4,   2,  67,\n",
       "         6,  34,  68,  69,  70,  71,  72,  22,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> castle battle reviewtitle love it reviewcontent this game is beautiful . nice one experience ! <end>\n",
      "Predicted translation: this game is repetitive . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "string = 'castle battle reviewtitle love it reviewcontent this game is beautiful. Nice one experience!'\n",
    "display(translate(string))#, guesses_number=10, width=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
